<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SmartEraser: Remove Anything from Images using Masked-Region Guidance</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SmartEraser: Remove Anything from Images using Masked-Region Guidance</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Longtao Jiang</a><sup>*1</sup>,</span>
              <span class="author-block">Zhendong Wang</a><sup>*1</sup>,</span>
              <span class="author-block">Jiangmin Bao</a><sup>*†2</sup>,</span>
              <br>
              <span class="author-block">Wengang Zhou</a><sup>†1</sup>,</span>
              <span class="author-block">Dongdong Chen</a><sup>2</sup>,</span>
              <span class="author-block">Lei Shi</a><sup>2</sup>,</span>
              <span class="author-block">Dong Chen</a><sup>2</sup>,</span>
              <span class="author-block">Houqiang Li</a><sup>1</sup>,</span>

                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                    <sup>1</sup>University of Science and Technology of China <sup>2</sup>Microsoft Research Asia</span>
                    <span class="author-block"><small>Email: taotao707@mail.ustc.edu.cn, zhendongwang6@outlook.com, jmbao@mail.ustc.edu.cn</small>
                        </span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution <sup>†</sup>Indicates Corresponding authors</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2501.08279" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/longtaojiang/SmartEraser" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2501.08279" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

 <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!--<video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>-->
        <img src="static/images/Teasor.jpg" />
        <div class="content has-text-justified">
          <p>
            Object removal results generated by SmartEraser using user-provided masks. 
            SmartEraser not only generates photorealistic images with the target objects 
            removed but also better preserves the surrounding context around the removed objects.
          </p>
        </div>

      </div>
    </div>
  </section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Object removal has so far been dominated by the mask-and-inpaint paradigm, 
            where the masked region is excluded from the input, leaving models relying on 
            unmasked areas to inpaint the missing region. However, this approach lacks 
            contextual information for the masked area, often resulting in unstable performance. 
            In this work, we introduce SmartEraser, built with a new removing 
            paradigm called Masked-Region Guidance. This paradigm retains the masked region 
            in the input, using it as guidance for the removal process. It offers several distinct 
            advantages: (a) it guides the model to accurately identify the object to be removed, 
            preventing its regeneration in the output; (b) since the user mask often extends beyond 
            the object itself, it aids in preserving the surrounding context in the final result. 
            Leveraging this new paradigm, we present Syn4Removal, a large-scale object removal dataset, 
            where instance segmentation data is used to copy and paste objects onto images as removal 
            targets, with the original images serving as ground truths. Experimental results demonstrate 
            that our model, SmartEraser, significantly outperforms existing methods, achieving superior 
            performance in object removal, especially in complex scenes with intricate compositions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section">
    <div class="container is-max-desktop">
      <div class="column is-full-width">
        <h3 class="title is-3">The Methods</h3>
        <h3 class="title is-4">Masked-Region Guidance Paradigm</h3>

        <div class="content has-text-justified has-text-centered">
        <p>we introduce a novel paradigm for object removal called Masked-Region Guidance. The core idea is that the masked region should not be excluded 
            but rather utilized as critical guidance during the removal process.
        </p>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="15%"></td>
              <td width="70%">
                <img src="static/images/introduction.jpg" />
                <p class="has-text-centered"> Comparison of the mask-and-inpaint paradigm and the proposed Masked-Region Guidance paradigm for object removal. </p>
              </td>
              <td width="15%"></td>
            </tr>
          </table> 
          <p>
            Our method is straightforward: instead of replacing the masked region with 
            a placeholder, we retain the original image as input, with the masked region indicated by a mask input, as in existing methods. This paradigm enables the model to accurately identify the target object, preventing unintended regeneration 
            in the output and effectively preserving the surrounding context of the target object in the final result.
          </p>

          <h3 class="title is-4">Syn4Removal Dataset</h3>
          <p>
            We introduce a synthetic technique to create training data specifically for object removal. Our approach involves pasting object instances from various images onto different background images to form the input images, with the pasted instance masks serving as the input masks and the original background images designated as ground truths. Using this method, we generate Syn4Removal, a large-scale dataset comprising triplets of real background images, masks, and backgrounds with pasted objects. The design of Syn4Removal provides diverse scenes and supports effective training under our new paradigm, encouraging the model to accurately learn object removal without shortcuts.
          </p>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="100%">
                <img src="static/images/dataset.jpg" />
                <p class="has-text-centered"> The data generation pipeline of Syn4Removal. We apply instances and images to construct a triplet 
                    consisting of an input image with removal targets, a mask, and the ground truth. </p>
              </td>
            </tr>
          </table>
          <p>
            To make Syn4Removal suitable for training object removal models, we design a pipeline to generate high-quality data. First, we filter out low-quality instances and background images. Then, we develop a method to calculate feasible pasting locations on the image, ensuring that objects do not overlap with instances in the pasted area, which helps prevent the model from regenerating unwanted objects. Last, the instance is pasted onto a background image with a blending algorithm. The resulting dataset consists of 1 million image triplets.
          </p>

          <h3 class="title is-4">SmartEraser Framework</h3>
          <p>
            Using the Masked-Region Guidance paradigm and the Syn4Removal dataset, we design a framework based on text-to-image diffusion models for object removal. To enhance the model's robustness to varying mask shapes from user input, we introduce a mask enhancement technique that simulates different mask shapes over removal targets. Additionally, we incorporate CLIP-based visual guidance to assist the model in better understanding the removal targets. The resulting model called SmartEraser outperforms previous methods significantly in both quantitative and qualitative evaluations. We choose the name SmartEraser because the model can smartly identify removal targets and remove it while preserving its surrounding region.
          </p>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="100%">
                <img src="static/images/model.jpg" />
                <p class="has-text-centered"> Overall framework of SmartEraser. It fully utilizes the Masked-Region Guidance paradigm and the Syn4Removal dataset. </p>
              </td>
            </tr>
          </table>
          <p>
            Based on the proposed Masked-Region Guidance paradigm and the Syn4Removal dataset, we design a framework based on the text-to-image stable diffusion model for object removal. In this framework, we carefully design a user-friendly mask enhancement strategy and introduce CLIP-based visual guidance to further improve the capability of the model for object removal.
          </p>

          <h3 class="title is-4">Mask Enhancement Types</h3>
          <p>
            In real-world scenarios, users usually provide a loose or tight mask around the object to be removed. If the model were trained only with precise object masks, there would be a significant gap in mask shape and size between training and inference. To address this, during training, we apply various mask deformation methods to simulate the user input mask shapes. These techniques help the model generalize to different mask forms. Specifically, we use six mask types to augment the object mask.
          </p>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="15%"></td>
              <td width="60%">
                <img src="static/images/mask_enhence.jpg" />
                <p class="has-text-centered"> Mask shapes from different mask enhancement methods. </p>
              </td>
              <td width="15%"></td>
            </tr>
          </table>
          <p>
          </p>
        </div>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <div class="column is-full-width">
        <h3 class="title is-3" style="margin-top: -30pt;">Comparasion with Previous Methods</h3>

        <h3 class="title is-4">Quantitative Results</h3>
        <div class="content has-text-justified has-text-centered">
          <p>
            We evaluate the object removal capability of all baseline methods and our approach across three benchmarks in diverse scenarios. The benchmarks are constructed as follows:
            RORD-Val: Due to there are many triplets share the same background images as the ground truth in validation set of the RORD. To ensure unique scenes and high object quality, we filter this subset to obtain RORD-Val, a evaluation benchmark of real-photography image pairs.
            DEFACTO-Val: Derived from the splicing section of DEFACTO, we exclude examples where intented targets for removal significantly overlap with instances in the background images.
            Syn4Removal-Val: Generated using the pipeline of Syn4Removal with MSCOCO validation set as background images and OpenImages-v7 validation set offering instances.
          </p>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="20%"></td>
              <td width="40%">
                <img src="static/images/1736406617377.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Quantitative comparison of SmartEraser and previous methods on RORD-Val</p>
              </td>
              <td width="20%"></td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="20%"></td>
              <td width="40%">
                <img src="static/images/1736406641855.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Quantitative comparison of SmartEraser and previous methods on DEFACTO-Val.</p>
              </td>
              <td width="20%"></td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="20%"></td>
              <td width="40%">
                <img src="static/images/1736406658006.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Quantitative comparison of SmartEraser and previous methods on Syn4Removal-Val.</p>
              </td>
              <td width="20%"></td>
            </tr>
          </table>

          <p>
            We conduct extensive experiments to evaluate the performance of SmartEraser against baselines on the benchmarks. SmartEraser significantly outperforms all other methods across all metrics on the three benchmarks.  
          </p>
        </div>

        <h3 class="title is-4">Qualitative Results</h3>
        <div class="content has-text-justified has-text-centered">
          <p>
            We present visualization comparison results of object removal using images from real scenes.
          </p>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="0%"></td>
              <td width="100%">
                <img src="static/images/1736406747836.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Qualitative comparison of SmartEraser and state-of-the-art methods. The samples are sourced from RORD-Val, which includes the ground truth after removal.</p>
              </td>
              <td width="0%"></td>
            </tr>
          </table>

          <div style="margin-top: -1em;">
            Baseline methods have limitations and may introduce unintended objects, create unrealistic structures, or produce artifacts within masked regions. In contrast, SmartEraser succeeds in effectively removing target objects while generating high-quality synthesized results, and excels in  maintaining the contextual integrity and visual coherence of the scene.
          </div>

        </div>
        <br/>


        <h3 class="title is-3" style="margin-top: 30pt;">Ablation Study</h3>
        <p>
            To evaluate the effectiveness of the key components in our framework, we perform ablation studies and report both quantitative and qualitative results. We progressively modify the baseline (fine-tuning SD v1.5 with the mask-and-inpaint paradigm) by adding our proposed techniques: RG for masked-region guidance, ME for mask enhancement, and VG for CLIP-based visual guidance.
        </p>
        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="20%"></td>
              <td width="35%">
                <img src="static/images/1736406770529.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Qualitative ablation comparison of our method. From left to right, we progressively add each proposed component.</p>
              </td>
              <td width="20%"></td>
            </tr>
          </table>
        
        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="20%"></td>
              <td width="35%">
                <img src="static/images/1736406788753.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Quantitative ablated comparison on RORD-Val.</p>
              </td>
              <td width="20%"></td>
            </tr>
          </table>


        <h3 class="title is-3" style="margin-top: 30pt;">More Useful Experiments</h3>
        <h4 class="title is-5">Real-world User Cases</h4>
        <p>
            To further evaluate the object removal capability of SmartEraser in real-world user scenarios, we conduct a comparison with other methods (LaMa, CLIPAway, PowerPaint), using masks provided by users. We can observe that SmartEraser exhibits a remarkable ability to accurately identify and remove target objects while preserving surrounding contextual details, particularly in scenarios involving imperfect or approximate masks.
        </p>
        <p>

        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="0%"></td>
              <td width="100%">
                <img src="static/images/1736406726748.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Qualitative comparison of SmartEraser and other methods in real-world user cases, in which users provide various mask shapes. The samples are sourced from real-world images and the validation set of MSCOCO.</p>
              </td>
              <td width="0%"></td>
            </tr>
          </table>
        </tr>
        </p>
        <br>

        <h4 class="title is-5">Comparisons with Instruction-Based Methods</h4>
        <p>
            We provide qualitative comparisons between instruction-based methods and our SmartEraser. Instruct-Pix2Pix struggles in removing objects, often failing to remove the target objects, instead, introducing unrealistic edits to the objects. Another work Inst-Inpaint demonstrates a basic capability for object removal, but it faces challenges in more complex cases, resulting in incomplete object removal and poor coherence between the removed area and the background, as observed in the first and second samples.
            In contrast, SmartEraser effectively removes target objects accurately and preserves high background consistency and overall image quality.
        </p>

        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="20%"></td>
              <td width="35%">
                <img src="static/images/1736406820482.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Qualitative comparison of SmartEraser and existing instruction-based image editing method, which only rely on user input prompts for object removal.</p>
              </td>
              <td width="20%"></td>
            </tr>
          </table>
          <br>

        <h4 class="title is-5"> Erasing Scene Text</h4>
        <p>
            We explore the capability of SmartEraser when applying it to erasing scene text. We observe that based on the proposed novel paradigm, our SmartEraser can remove scene text seamlessly without hurting the surrounding context.
        </p>
        <br>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td width="20%"></td>
              <td width="35%">
                <img src="static/images/1736406838129.jpg" />
                <p class="has-text-centered" style="margin-top: -0.5em;">Qualitative result of our method for erasing scene text.</p>
              </td>
              <td width="20%"></td>
            </tr>
          </table>

        <br />

<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->

<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{jiang2025smarteraserremoveimagesusing,
        title={SmartEraser: Remove Anything from Images using Masked-Region Guidance}, 
        author={Longtao Jiang and Zhendong Wang and Jianmin Bao and Wengang Zhou and Dongdong Chen and Lei Shi and Dong Chen and Houqiang Li},
        year={2025},
        eprint={2501.08279},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2501.08279}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
